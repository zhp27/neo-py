# -*- coding: utf-8 -*-
"""
Created on Sat Feb 13 20:18:17 2021

@author: raha_

"""
'''
doc=nlp("The 22-year-old recently won ATP Challenger tournament")
for tok in doc:
    print(tok.text,"...",tok.dep_)'''
    
import spacy
import re
import pandas as pd
import bs4
from spacy import displacy
nlp=spacy.load('en_core_web_sm')
from spacy.matcher import Matcher
from spacy.tokens import Span
import networkx as nx
import matplotlib.pyplot as plt
from tqdm import tqdm
from neo4j import GraphDatabase
import pickle

class HelloWorldExample:

    def __init__(self, uri, user, password):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def close(self):
        self.driver.close()

    def print_greeting(self, message):
        with self.driver.session() as session:
            greeting = session.write_transaction(self._create_and_return_greeting, message)
            print(greeting)

    @staticmethod
    def _create_and_return_greeting(tx, message):
        result = tx.run("CREATE (b:Greeting) "
                        "SET b.message = $message "
                        "RETURN b.message + ', from node ' + id(b)", message=message)
        return result.single()[0]


def get_entities(sent):
    #chunk 1
    ent1=""
    ent2=""
    prv_tok_dep="" #Dependency tag of previous token
    prv_tok_text="" #previous token in the sntence
    prefix=""
    modifier=""
    for tok in nlp(sent):
        #chunk2
        #if token is a punctuation mark move to the next
        if tok.dep_ != "punct":
            #token is a compound word or not
            if tok.dep_ == "compound":
                #if the previous  token is also compound then add them to gather
                if prv_tok_dep == "compound":
                    prefix=prv_tok_text + " " + tok.text
            #check: token is modifier  or not
            if tok.dep_.endswith("mod") == True:
                modifier=tok.text
                # if the previous word is also compound add them
                if prv_tok_dep == "compound":
                    modifier = prv_tok_text + " " + tok.text
            #chunk 3
            if tok.dep_.find("subj") == True:
                ent1 = modifier + " " + prefix + " " + tok.text
                prefix = ""
                modifier = ""
                prv_tok_dep= ""
                prv_tok_text= ""
             
            #chunk4
            if tok.dep_.find("obj") == True:
                ent2 = modifier + " " + prefix + " " + tok.text
                
            #chunk 5
            #update vars
            prv_tok_dep = tok.dep_
            prv_tok_text
    return [ent1.strip(), ent2.strip()]

def get_relation(sent):

  doc = nlp(sent)

  # Matcher class object 
  matcher = Matcher(nlp.vocab)

  #define the pattern 
  pattern = [{'DEP':'ROOT'}, 
            {'DEP':'prep','OP':"?"},
            {'DEP':'agent','OP':"?"},  
            {'POS':'ADJ','OP':"?"}] 

  matcher.add("matching_1", None, pattern) 

  matches = matcher(doc)
  k = len(matches) - 1

  span = doc[matches[k][1]:matches[k][2]] 

  return(span.text)


pd.set_option('display.max_colwidth',200)
%matplotlib inline
candidateSentence = pd.read_csv("wiki_sentences_v2.csv")
#print(candidateSentence.shape)
#print(candidateSentence['sentence'].sample(5)) 
#ent= get_entities("the lifeboats and funnels were shrunken by ten percent.ent")
entityPairs = []
for i in tqdm(candidateSentence["sentence"]):
    entityPairs.append(get_entities(i))
#get_relation("John compeleted the task")
relations=[get_relation(i) for i in tqdm (candidateSentence['sentence'])]

#build knowledge graph
#extract subject
source=[i[0] for i in entityPairs]
#extract object
target=[i[1] for i in entityPairs]
kgDf=pd.DataFrame({'source':source, 'target':target, 'edge':relations})

f = open('store.pckl', 'wb')
pickle.dump(kgDf, f)
f.close()


if __name__ == "__main__":
    greeter = HelloWorldExample("bolt://localhost:7687", "neo4j", "123456")
    greeter.print_greeting("hello, world")
    greeter.close()


'''gr=nx.from_pandas_edgelist(kgDf, "source","target",
                           edge_attr=True, create_using=nx.MultiDiGraph())
plt.figure(figsize=(12,12))
pos=nx.spring_layout(gr)
nx.draw(gr,with_labels=True, node_color='skyblue',edge_camp=plt.cm.Blues, pos=pos)
'''
'''
gr=nx.from_pandas_edgelist(kgDf[kgDf['edge']=="composed by"], "source","target",
                           edge_attr=True, create_using=nx.MultiDiGraph())
plt.figure(figsize=(12,12))
pos=nx.spring_layout(gr, k=0.5) #k regulates distance of nodes
nx.draw(gr,with_labels=True, node_color='skyblue', node_size=1500,edge_camp=plt.cm.Blues, pos=pos)
'''
